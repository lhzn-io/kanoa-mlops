{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart: Molmo 7B with vLLM on GCP\n",
    "\n",
    "This notebook walks you through deploying a vLLM server with the **Molmo-7B-D-0924** model on Google Cloud Platform.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Google Cloud Project** with billing enabled\n",
    "- **gcloud CLI** authenticated (`gcloud auth application-default login`)\n",
    "- **Terraform** >= 1.5.0 installed\n",
    "- **kanoa** library installed (`pip install kanoa`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure Your Project\n",
    "\n",
    "Set your GCP project ID below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Configure your GCP project\n",
    "PROJECT_ID = \"your-gcp-project-id\"  # <-- CHANGE THIS\n",
    "\n",
    "# Optional: Override region (default: us-central1)\n",
    "REGION = \"us-central1\"\n",
    "\n",
    "os.environ[\"TF_VAR_project_id\"] = PROJECT_ID\n",
    "os.environ[\"TF_VAR_region\"] = REGION\n",
    "\n",
    "print(f\"Project: {PROJECT_ID}\")\n",
    "print(f\"Region:  {REGION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deploy Infrastructure\n",
    "\n",
    "Initialize Terraform and deploy the Molmo preset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../infrastructure/gcp\n",
    "\n",
    "# Initialize Terraform (only needed once)\n",
    "terraform init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../infrastructure/gcp\n",
    "\n",
    "# Deploy using Molmo preset\n",
    "terraform apply -var-file=presets/molmo-7b.tfvars -auto-approve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get API Endpoint\n",
    "\n",
    "Retrieve the vLLM server URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "result = subprocess.run(\n",
    "    [\"terraform\", \"output\", \"-json\"],\n",
    "    cwd=\"../infrastructure/gcp\",\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "outputs = json.loads(result.stdout)\n",
    "\n",
    "API_ENDPOINT = outputs[\"api_endpoint\"][\"value\"]\n",
    "print(f\"API Endpoint: {API_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Wait for Server Ready\n",
    "\n",
    "The vLLM server takes ~3-5 minutes to download and load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "def wait_for_server(endpoint, timeout=600):\n",
    "    health_url = f\"{endpoint}/health\"\n",
    "    start = time.time()\n",
    "    print(f\"Waiting for server at {health_url}...\")\n",
    "    while time.time() - start < timeout:\n",
    "        try:\n",
    "            resp = requests.get(health_url, timeout=5)\n",
    "            if resp.status_code == 200:\n",
    "                print(f\"Server ready! ({int(time.time() - start)}s)\")\n",
    "                return True\n",
    "        except requests.RequestException:\n",
    "            pass\n",
    "        print(\".\", end=\"\", flush=True)\n",
    "        time.sleep(10)\n",
    "    print(f\"Timeout after {timeout}s\")\n",
    "    return False\n",
    "\n",
    "\n",
    "wait_for_server(API_ENDPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Inference with kanoa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kanoa.backends.vllm import VLLMBackend\n",
    "\n",
    "backend = VLLMBackend(api_base=API_ENDPOINT, model=\"allenai/Molmo-7B-D-0924\")\n",
    "print(f\"Connected to: {backend.model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple text query\n",
    "response = backend.generate(\n",
    "    prompt=\"What is machine learning? Explain in 2 sentences.\", max_tokens=100\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image analysis (Molmo is multimodal!)\n",
    "response = backend.generate(\n",
    "    prompt=\"Describe this image in detail.\",\n",
    "    images=[\n",
    "        \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\"\n",
    "    ],\n",
    "    max_tokens=200,\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cost Tracking\n",
    "\n",
    "L4 GPU: ~$0.70/hour. Server has 30-min idle timeout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup\n",
    "\n",
    "**Important**: Destroy when done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd ../infrastructure/gcp\n",
    "terraform destroy -var-file=presets/molmo-7b.tfvars -auto-approve"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
