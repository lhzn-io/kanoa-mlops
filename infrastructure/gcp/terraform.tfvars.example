# -----------------------------------------------------------------------------
# kanoa-mlops GCP Terraform Variables
# Copy this file to terraform.tfvars and fill in your values
# -----------------------------------------------------------------------------

# Required: Your GCP project ID
project_id = "your-gcp-project-id"

# Required: Your IP address for SSH/API access (CIDR notation)
# Get your IP: curl -s ifconfig.me
# Example: ["203.0.113.50/32"] for single IP
# Example: ["203.0.113.0/24"] for IP range
allowed_source_ranges = ["YOUR_IP/32"]

# Optional: Region and zone
# See available zones with L4 GPUs: 
# gcloud compute accelerator-types list --filter="name=nvidia-l4"
region = "us-central1"
zone   = "us-central1-a"

# Optional: Model configuration
model_name    = "allenai/Molmo-7B-D-0924"
max_model_len = 4096

# Optional: HuggingFace token (for gated models like Llama)
# hf_token = "hf_xxxxxxxxxxxxxxxxxxxxx"

# Optional: Auto-shutdown after idle (minutes, 0 to disable)
idle_timeout_minutes = 30

# Optional: Instance schedule (auto start/stop at specific times)
enable_schedule     = false
schedule_start_time = "0 9 * * 1-5"   # 9 AM Mon-Fri
schedule_stop_time  = "0 18 * * 1-5"  # 6 PM Mon-Fri
schedule_timezone   = "America/Los_Angeles"

# Optional: Machine configuration
# g2-standard-8 = 8 vCPU, 32GB RAM, 1x L4 GPU (~$0.70/hr)
# g2-standard-16 = 16 vCPU, 64GB RAM, 1x L4 GPU (~$1.00/hr)
machine_type      = "g2-standard-8"
boot_disk_size_gb = 200

# Optional: Labels for resource organization
labels = {
  project     = "kanoa-mlops"
  environment = "dev"
  owner       = "your-name"
}
